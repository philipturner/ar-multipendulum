# AR MultiPendulum: AR Headset Experience

AR MultiPendulum allows users to interact with virtual objects directly with their hand instead of tapping an object's location on a touchscreen. It brings a mesmerizing multi-pendulum simulation into augmented reality. Users interact with this simulation through hand movements and modify it through a holographic interface.

Not only does this app bring augmented reality to a pendulum simulation, it is also the first app to simulate more than three pendulums. Additionally, by repurposing a VR headset for AR, this is the first app that gives users an affordable AR headset experience. If a user has Google Cardboard, they can turn their iPhone into an AR headset that renders their surroundings in VR, based on images acquired using their deviceâ€™s camera.

Some of the latest iPhones and iPads have a built-in LiDAR scanner, which allows a device to understand the 3D shape of its surroundings. On these devices, this app uses the scanner to more realistically render the user's surroundings and reconstruct the 3D position of their hand.

This app is available for free on the [App Store](https://apps.apple.com/app/ar-multipendulum/id1583322801). To learn more about how this app was created, check out [Creating the World's First Affordable AR Headset Experience](https://github.com/philipturner/first-affordable-ar-headset). There is a [browser version](https://github.com/philipturner/multipendulum) of the multi-pendulum simulation.

This repository contains source code created during [this](https://github.com/philipturner/scene-color-reconstruction) research on real-time scene color reconstruction. This source code uses the term "mixed reality" (MR) to differentiate code that generates the handheld experience from code that generates the headset experience. This term is a synonym for augmented reality often used to describe AR headset experiences.


